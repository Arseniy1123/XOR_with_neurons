import numpy as np
import matplotlib.pyplot as plt

# Активационная функция - сигмоида (ее формула: f(x) = 1 / (1 + e^(-x)))
def sigmoid(x):
    return 1 / (1 + np.exp(-x))
# Производная активационной функции (сигмоиды)
def sigmoid_deriv(x):
    return sigmoid(x) * (1 - sigmoid(x))

def forward(X, w1, w2, predict = False):
    a1 = np.matmul(X, w1) # Матричное произведение двух массивов (входные данные на вес 1)
    z1 = sigmoid(a1)

    # Нужно добавить "1" ко всему набору входных данных, потому что нужно учесть
    # bias - нейрон смещения
    bias = np.ones((len(z1), 1)) 
    z1 = np.concatenate((bias, z1), axis = 1)

    # Матричное произведение двух массивов (данные с учетом bias на вес 2)
    a2 = np.matmul(z1, w2) 
    z2 = sigmoid(a2)

    # Для вывода массива полученных значений после работы программы (реальных и округленных)
    if predict: 
        return z2
    
    return a1, z1, a2, z2

# Обратное распространение ошибки (для корректировки значений весов)
def backprop(a2, X, z1, z2, y):

    delta2 = z2 - y
    Delta2 = np.matmul(z1.T, delta2) # Матричное произведение двух массивов
    delta1 = delta2.dot(w2[1:,:].T)
    delta1 *= sigmoid_deriv(a1)
    Delta1 = np.matmul(X.T, delta1) # Матричное произведение двух массивов 

    return delta2, Delta1, Delta2

# Набор входных данных (первый столбец - bias, нужно смотреть на 2 и 3 столбцы)
X = np.array([[1, 1, 0],
              [1, 0, 1],
              [1, 0, 0],
              [1, 1, 1]])

# Набор выходных данных (правильные значния после выполнения операции XOR
# между значениями второго и третьего столбцов входных данных (Х))
y = np.array([[1], [1], [0], [0]])

# Случайная инициализация значений весов
w1 = np.random.randn(3, 5)
w2 = np.random.randn(6, 1)

# Коэффициент скорости обучения (чем он больше, тем больше вероятность, что значение
# будет посчитано ошибочно, однако в таком случае (чем больше lr), тем быстрее можно
# работает алгоритм)

lr = 0.09 

# Для показа графика зависимости значения ошибки от числа итераций
costs = []

# Количество итераций
n = 15000

# Длина набора входных данных (нужна для корректировки весов)
m = len(X)

for i in range(n):

    a1, z1, a2, z2 = forward(X, w1, w2)

    delta2, Delta1, Delta2 = backprop(a2, X, z1, z2, y)

    # Корректировка весов по мере прохождения итераций
    w1 -= lr * (1 / m) * Delta1
    w2 -= lr * (1 / m) * Delta2

    c = np.mean(np.abs(delta2))
    costs.append(c)

    # Как только проходим очередную 1000 итераций, выводится значение текущей ошибки
    if i % 1000 == 0:
        print(f"Iteration: {i}. Error: {c}")

print()

# Вывод результатов работы программы
z3 = forward(X, w1, w2, True)
print("Не округленные значения (реальные): ")
print(z3)
print("Округленные значения: ")
print(np.round(z3))

plt.plot(costs)
plt.title('Зависимость значений ошибки от количества итераций') # Название графика
plt.xlabel('Количество итераций') # Ось Х
plt.ylabel('Значение ошибки') # Ось Y
plt.show()
    









